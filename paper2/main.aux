\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\abx@aux@refcontext{nyt/global//global/global}
\abx@aux@refcontext{nyt/apasortcite//global/global}
\abx@aux@cite{0}{bengio1994learning}
\abx@aux@segm{0}{0}{bengio1994learning}
\abx@aux@refcontext{nyt/apasortcite//global/global}
\abx@aux@cite{0}{hochreiter1997lstm}
\abx@aux@segm{0}{0}{hochreiter1997lstm}
\abx@aux@refcontext{nyt/apasortcite//global/global}
\abx@aux@cite{0}{cho2014properties}
\abx@aux@segm{0}{0}{cho2014properties}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{2}{section.1}\protected@file@percent }
\abx@aux@page{1}{2}
\abx@aux@page{2}{2}
\abx@aux@page{3}{2}
\abx@aux@refcontext{nyt/apasortcite//global/global}
\abx@aux@cite{0}{werbos1990bptt}
\abx@aux@segm{0}{0}{werbos1990bptt}
\abx@aux@refcontext{nyt/apasortcite//global/global}
\abx@aux@cite{0}{rumelhart1986backpropagation}
\abx@aux@segm{0}{0}{rumelhart1986backpropagation}
\abx@aux@refcontext{nyt/apasortcite//global/global}
\abx@aux@cite{0}{werbos1990bptt}
\abx@aux@segm{0}{0}{werbos1990bptt}
\@writefile{toc}{\contentsline {section}{\numberline {2}Background and Literature Review}{3}{section.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Evolution of Deep Learning and Recurrent Neural Networks}{3}{subsection.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Literature Review}{3}{subsection.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.1}Backpropagation Through Time}{3}{subsubsection.2.2.1}\protected@file@percent }
\abx@aux@page{4}{3}
\abx@aux@page{5}{3}
\abx@aux@page{6}{3}
\gdef \LT@i {\LT@entry 
    {1}{64.36809pt}\LT@entry 
    {1}{253.32529pt}\LT@entry 
    {1}{180.16806pt}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Unfolded RNN}}{4}{figure.1}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {1}{Unfolded RNN}}{4}{table.1}\protected@file@percent }
\abx@aux@refcontext{nyt/apasortcite//global/global}
\abx@aux@cite{0}{wikipedia2023bptt}
\abx@aux@segm{0}{0}{wikipedia2023bptt}
\abx@aux@page{7}{7}
\@writefile{loa}{\contentsline {algorithm}{\numberline {1}{\ignorespaces Backpropagation Through Time (BPTT)}}{7}{algorithm.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.2}Activation Function}{7}{subsubsection.2.2.2}\protected@file@percent }
\abx@aux@refcontext{nyt/apasortcite//global/global}
\abx@aux@cite{0}{bengio1994learning}
\abx@aux@segm{0}{0}{bengio1994learning}
\abx@aux@refcontext{nyt/apasortcite//global/global}
\abx@aux@cite{0}{hochreiter1997lstm}
\abx@aux@segm{0}{0}{hochreiter1997lstm}
\abx@aux@refcontext{nyt/apasortcite//global/global}
\abx@aux@cite{0}{hochreiter1997lstm}
\abx@aux@segm{0}{0}{hochreiter1997lstm}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.3}Gradient vanishing and gradient exploring}{9}{subsubsection.2.2.3}\protected@file@percent }
\abx@aux@page{8}{9}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.4}Long short-term memory (LSTM)}{9}{subsubsection.2.2.4}\protected@file@percent }
\abx@aux@page{9}{9}
\abx@aux@refcontext{nyt/apasortcite//global/global}
\abx@aux@cite{0}{hochreiter1997lstm}
\abx@aux@segm{0}{0}{hochreiter1997lstm}
\abx@aux@page{10}{10}
\abx@aux@page{11}{10}
\gdef \LT@ii {\LT@entry 
    {1}{64.36809pt}\LT@entry 
    {1}{244.38232pt}\LT@entry 
    {1}{77.8466pt}}
\@writefile{lot}{\contentsline {table}{\numberline {2}{Unfolded RNN}}{11}{table.2}\protected@file@percent }
\abx@aux@refcontext{nyt/apasortcite//global/global}
\abx@aux@cite{0}{cho2014properties}
\abx@aux@segm{0}{0}{cho2014properties}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.5}Gated Recurrent Unit (GRU)}{12}{subsubsection.2.2.5}\protected@file@percent }
\abx@aux@page{12}{12}
\gdef \LT@iii {\LT@entry 
    {1}{64.36809pt}\LT@entry 
    {1}{244.38232pt}\LT@entry 
    {1}{77.8466pt}}
\abx@aux@refcontext{nyt/apasortcite//global/global}
\abx@aux@cite{0}{bengio2009learning}
\abx@aux@segm{0}{0}{bengio2009learning}
\abx@aux@refcontext{nyt/apasortcite//global/global}
\abx@aux@cite{0}{le2010deep}
\abx@aux@segm{0}{0}{le2010deep}
\abx@aux@cite{0}{delalleau2011shallow}
\abx@aux@segm{0}{0}{delalleau2011shallow}
\abx@aux@cite{0}{pascanu2013on}
\abx@aux@segm{0}{0}{pascanu2013on}
\abx@aux@refcontext{nyt/apasortcite//global/global}
\abx@aux@cite{0}{roberts2004general}
\abx@aux@segm{0}{0}{roberts2004general}
\abx@aux@cite{0}{rabiner1986anintroduction}
\abx@aux@segm{0}{0}{rabiner1986anintroduction}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.6}Deep recurrent neural networks (DRNNs)}{14}{subsubsection.2.2.6}\protected@file@percent }
\abx@aux@page{13}{14}
\abx@aux@page{14}{14}
\abx@aux@page{15}{14}
\abx@aux@page{16}{14}
\abx@aux@refcontext{nyt/apasortcite//global/global}
\abx@aux@cite{0}{rabiner1989atutorial}
\abx@aux@segm{0}{0}{rabiner1989atutorial}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.7}Hidden Markov Model}{15}{subsubsection.2.2.7}\protected@file@percent }
\abx@aux@page{17}{15}
\abx@aux@page{18}{15}
\abx@aux@refcontext{nyt/apasortcite//global/global}
\abx@aux@cite{0}{rabiner1993fundamentals}
\abx@aux@segm{0}{0}{rabiner1993fundamentals}
\abx@aux@refcontext{nyt/apasortcite//global/global}
\abx@aux@cite{0}{sengupta2023hybrid}
\abx@aux@segm{0}{0}{sengupta2023hybrid}
\abx@aux@page{19}{16}
\abx@aux@page{20}{16}
\abx@aux@page{21}{16}
\abx@aux@refcontext{nyt/apasortcite//global/global}
\abx@aux@cite{0}{rabiner1993fundamentals}
\abx@aux@segm{0}{0}{rabiner1993fundamentals}
\abx@aux@refcontext{nyt/apasortcite//global/global}
\abx@aux@cite{0}{mikolov2013efficient}
\abx@aux@segm{0}{0}{mikolov2013efficient}
\abx@aux@page{22}{17}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.8}Word representation}{17}{subsubsection.2.2.8}\protected@file@percent }
\abx@aux@page{23}{17}
\@writefile{toc}{\contentsline {section}{\numberline {3}Project Goals and Objectives}{18}{section.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Project Goals}{18}{subsection.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Objectives}{18}{subsection.3.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.2.1}Implement Existing RNN Architectures}{18}{subsubsection.3.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.2.2}Apply the Models on a Benchmark NLP Dataset}{18}{subsubsection.3.2.2}\protected@file@percent }
\abx@aux@refcontext{nyt/apasortcite//global/global}
\abx@aux@cite{0}{maas-EtAl:2011:ACL-HLT2011}
\abx@aux@segm{0}{0}{maas-EtAl:2011:ACL-HLT2011}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.2.3}Compare Model Performances}{19}{subsubsection.3.2.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.2.4}Analyze the Impact of Architectural Differences}{19}{subsubsection.3.2.4}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4}Research Plan / Methodology}{19}{section.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Literature Review}{19}{subsection.4.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Data Collection and Preprocessing}{19}{subsection.4.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.2.1}Data Collection}{19}{subsubsection.4.2.1}\protected@file@percent }
\abx@aux@page{24}{19}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.2.2}Data Preprocessing}{19}{subsubsection.4.2.2}\protected@file@percent }
\abx@aux@refcontext{nyt/apasortcite//global/global}
\abx@aux@cite{0}{mikolov2013efficient}
\abx@aux@segm{0}{0}{mikolov2013efficient}
\abx@aux@page{25}{20}
\@writefile{lot}{\contentsline {table}{\numberline {4}{\ignorespaces Word to Index Mapping Table}}{20}{table.4}\protected@file@percent }
\newlabel{tab:word_index}{{4}{20}{Word to Index Mapping Table}{table.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3}Model Architecture}{20}{subsection.4.3}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {5}{\ignorespaces Word to Index Matching with Lookup Table Embeddings}}{21}{table.5}\protected@file@percent }
\newlabel{tab:word_lookup}{{5}{21}{Word to Index Matching with Lookup Table Embeddings}{table.5}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.3.1}Model 1 (Vanilla RNN)}{21}{subsubsection.4.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.3.2}Model 2 (Long short-term memory)}{22}{subsubsection.4.3.2}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Step 1: Initialize Hidden and Cell States}{22}{section*.2}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Step 2: Process Each Input Vector}{22}{section*.3}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Step 3: Compute Forget Gate}{23}{section*.4}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Step 4: Compute Input Gate}{23}{section*.5}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Step 5: Compute Cell Candidate}{23}{section*.6}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Step 6: Update Cell State}{23}{section*.7}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Step 7: Compute Output Gate}{23}{section*.8}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Step 8: Compute Hidden State}{24}{section*.9}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Step 9: Use Final Hidden State for Output}{24}{section*.10}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.3.3}Model 3 (Gated recurrent unit)}{24}{subsubsection.4.3.3}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Step 1: Initialize Hidden State}{24}{section*.11}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Step 2: Process Each Input Vector}{24}{section*.12}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Step 3: Compute Reset Gate}{25}{section*.13}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Step 4: Compute Update Gate}{25}{section*.14}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Step 5: Compute Candidate Hidden State}{25}{section*.15}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Step 6: Update Hidden State}{25}{section*.16}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Step 7: Use Final Hidden State for Output}{26}{section*.17}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4}Training, Hyperparameter Tuning, and Evaluation}{27}{subsection.4.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.4.1}Model Hyperparameters and Setup}{27}{subsubsection.4.4.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.4.2}Training Loop Overview}{27}{subsubsection.4.4.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.4.3}Pseudocode Description}{28}{subsubsection.4.4.3}\protected@file@percent }
\@writefile{lol}{\contentsline {lstlisting}{\numberline {1}Training Loop Pseudocode}{28}{lstlisting.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {5}Results and Analysis}{30}{section.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1}Results}{30}{subsection.5.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.1.1}Vanilla RNN}{30}{subsubsection.5.1.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces RNN performance on IMDB dataset}}{30}{figure.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.1.2}GRU}{30}{subsubsection.5.1.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces GRU performance on IMDB dataset}}{31}{figure.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.1.3}LSTM}{31}{subsubsection.5.1.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces LSTM performance on IMDB dataset}}{31}{figure.4}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {6}Analysis}{32}{section.6}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.1}Learning Behavior}{32}{subsection.6.1}\protected@file@percent }
\abx@aux@page{26}{33}
\abx@aux@page{27}{33}
\abx@aux@page{28}{33}
\abx@aux@page{29}{33}
\abx@aux@page{30}{33}
\abx@aux@page{31}{33}
\abx@aux@page{32}{33}
\abx@aux@page{33}{33}
\abx@aux@page{34}{33}
\abx@aux@page{35}{33}
\abx@aux@page{36}{33}
\abx@aux@page{37}{33}
\abx@aux@page{38}{33}
\abx@aux@page{39}{33}
\abx@aux@page{40}{33}
\abx@aux@page{41}{33}
\abx@aux@page{42}{33}
\abx@aux@read@bbl@mdfivesum{10F21A56D22777569AC0C389AD3D6209}
\abx@aux@defaultrefcontext{0}{bengio2009learning}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{bengio1994learning}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{cho2014properties}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{delalleau2011shallow}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{hochreiter1997lstm}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{le2010deep}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{maas-EtAl:2011:ACL-HLT2011}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{mikolov2013efficient}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{pascanu2013on}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{rabiner1986anintroduction}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{rabiner1989atutorial}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{rabiner1993fundamentals}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{roberts2004general}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{rumelhart1986backpropagation}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{sengupta2023hybrid}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{werbos1990bptt}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{wikipedia2023bptt}{nyt/global//global/global}
\gdef \@abspage@last{33}
