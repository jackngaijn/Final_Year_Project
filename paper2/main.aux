\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\abx@aux@refcontext{nyt/global//global/global}
\abx@aux@refcontext{nyt/apasortcite//global/global}
\abx@aux@cite{0}{bengio1994learning}
\abx@aux@segm{0}{0}{bengio1994learning}
\abx@aux@refcontext{nyt/apasortcite//global/global}
\abx@aux@cite{0}{hochreiter1997lstm}
\abx@aux@segm{0}{0}{hochreiter1997lstm}
\abx@aux@refcontext{nyt/apasortcite//global/global}
\abx@aux@cite{0}{cho2014properties}
\abx@aux@segm{0}{0}{cho2014properties}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{2}{section.1}\protected@file@percent }
\abx@aux@page{1}{2}
\abx@aux@page{2}{2}
\abx@aux@page{3}{2}
\@writefile{toc}{\contentsline {section}{\numberline {2}Background and Literature Review}{3}{section.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Evolution of Deep Learning and Recurrent Neural Networks}{3}{subsection.2.1}\protected@file@percent }
\abx@aux@refcontext{nyt/apasortcite//global/global}
\abx@aux@cite{0}{werbos1990bptt}
\abx@aux@segm{0}{0}{werbos1990bptt}
\abx@aux@refcontext{nyt/apasortcite//global/global}
\abx@aux@cite{0}{rumelhart1986backpropagation}
\abx@aux@segm{0}{0}{rumelhart1986backpropagation}
\abx@aux@refcontext{nyt/apasortcite//global/global}
\abx@aux@cite{0}{werbos1990bptt}
\abx@aux@segm{0}{0}{werbos1990bptt}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Literature Review}{4}{subsection.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.1}Backpropagation Through Time}{4}{subsubsection.2.2.1}\protected@file@percent }
\abx@aux@page{4}{4}
\abx@aux@page{5}{4}
\abx@aux@page{6}{4}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Unfolded RNN}}{4}{figure.1}\protected@file@percent }
\gdef \LT@i {\LT@entry 
    {1}{64.36809pt}\LT@entry 
    {1}{253.32529pt}\LT@entry 
    {1}{180.16806pt}}
\@writefile{lot}{\contentsline {table}{\numberline {1}{Unfolded RNN}}{5}{table.1}\protected@file@percent }
\abx@aux@refcontext{nyt/apasortcite//global/global}
\abx@aux@cite{0}{wikipedia2023bptt}
\abx@aux@segm{0}{0}{wikipedia2023bptt}
\abx@aux@page{7}{7}
\@writefile{loa}{\contentsline {algorithm}{\numberline {1}{\ignorespaces Backpropagation Through Time (BPTT)}}{7}{algorithm.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.2}Activation Function}{8}{subsubsection.2.2.2}\protected@file@percent }
\newlabel{fig:sigmoid}{{2.2.2}{8}{Activation Function}{equation.2.25}{}}
\newlabel{fig:tanh}{{2.2.2}{9}{Activation Function}{equation.2.27}{}}
\abx@aux@refcontext{nyt/apasortcite//global/global}
\abx@aux@cite{0}{bengio1994learning}
\abx@aux@segm{0}{0}{bengio1994learning}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.3}Gradient vanishing and gradient exploring}{10}{subsubsection.2.2.3}\protected@file@percent }
\abx@aux@page{8}{10}
\abx@aux@refcontext{nyt/apasortcite//global/global}
\abx@aux@cite{0}{hochreiter1997lstm}
\abx@aux@segm{0}{0}{hochreiter1997lstm}
\abx@aux@refcontext{nyt/apasortcite//global/global}
\abx@aux@cite{0}{hochreiter1997lstm}
\abx@aux@segm{0}{0}{hochreiter1997lstm}
\abx@aux@refcontext{nyt/apasortcite//global/global}
\abx@aux@cite{0}{hochreiter1997lstm}
\abx@aux@segm{0}{0}{hochreiter1997lstm}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.4}Long short-term memory (LSTM)}{11}{subsubsection.2.2.4}\protected@file@percent }
\abx@aux@page{9}{11}
\abx@aux@page{10}{11}
\abx@aux@page{11}{11}
\gdef \LT@ii {\LT@entry 
    {1}{64.36809pt}\LT@entry 
    {1}{244.38232pt}\LT@entry 
    {1}{77.8466pt}}
\@writefile{lot}{\contentsline {table}{\numberline {2}{Unfolded RNN}}{12}{table.2}\protected@file@percent }
\abx@aux@refcontext{nyt/apasortcite//global/global}
\abx@aux@cite{0}{cho2014properties}
\abx@aux@segm{0}{0}{cho2014properties}
\gdef \LT@iii {\LT@entry 
    {1}{64.36809pt}\LT@entry 
    {1}{244.38232pt}\LT@entry 
    {1}{77.8466pt}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.5}Gated Recurrent Unit (GRU)}{14}{subsubsection.2.2.5}\protected@file@percent }
\abx@aux@page{12}{14}
\abx@aux@refcontext{nyt/apasortcite//global/global}
\abx@aux@cite{0}{bengio2009learning}
\abx@aux@segm{0}{0}{bengio2009learning}
\abx@aux@refcontext{nyt/apasortcite//global/global}
\abx@aux@cite{0}{le2010deep}
\abx@aux@segm{0}{0}{le2010deep}
\abx@aux@cite{0}{delalleau2011shallow}
\abx@aux@segm{0}{0}{delalleau2011shallow}
\abx@aux@cite{0}{pascanu2013on}
\abx@aux@segm{0}{0}{pascanu2013on}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.6}Deep recurrent neural networks (DRNNs)}{16}{subsubsection.2.2.6}\protected@file@percent }
\abx@aux@page{13}{16}
\abx@aux@page{14}{16}
\abx@aux@page{15}{16}
\abx@aux@page{16}{16}
\abx@aux@refcontext{nyt/apasortcite//global/global}
\abx@aux@cite{0}{roberts2004general}
\abx@aux@segm{0}{0}{roberts2004general}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.7}Hidden Markov Model}{17}{subsubsection.2.2.7}\protected@file@percent }
\abx@aux@page{17}{17}
\abx@aux@refcontext{nyt/apasortcite//global/global}
\abx@aux@cite{0}{rabiner1989atutorial}
\abx@aux@segm{0}{0}{rabiner1989atutorial}
\abx@aux@page{18}{18}
\abx@aux@read@bbl@mdfivesum{AD446B7082DB032E3242F1A175A09681}
\gdef \@abspage@last{21}
