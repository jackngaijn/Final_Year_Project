{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import AutoTokenizer\n",
    "from datasets import load_dataset\n",
    "import numpy as np\n",
    "\n",
    "# Step 1: Load the SQuAD dataset\n",
    "squad = load_dataset(\"squad\")\n",
    "\n",
    "# Extract data\n",
    "train_data = squad['train']\n",
    "contexts = [item['context'] for item in train_data]\n",
    "questions = [item['question'] for item in train_data]\n",
    "answers = [item['answers']['text'][0] for item in train_data]\n",
    "answer_starts = [item['answers']['answer_start'][0] for item in train_data]\n",
    "\n",
    "# Step 2: Preprocess the data\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "# Tokenize context and question\n",
    "def preprocess_data(context, question, answer, answer_start):\n",
    "    tokenized_context = tokenizer(context, truncation=True, padding=\"max_length\", max_length=300, return_tensors=\"pt\")\n",
    "    tokenized_question = tokenizer(question, truncation=True, padding=\"max_length\", max_length=50, return_tensors=\"pt\")\n",
    "    \n",
    "    # Compute answer tokens\n",
    "    answer_end = answer_start + len(answer)\n",
    "    token_start = tokenized_context.char_to_token(answer_start)\n",
    "    token_end = tokenized_context.char_to_token(answer_end - 1)\n",
    "    \n",
    "    if token_start is None or token_end is None:\n",
    "        # If the answer cannot be tokenized, return None (to filter out later)\n",
    "        return None\n",
    "    \n",
    "    return {\n",
    "        \"context\": tokenized_context[\"input_ids\"].squeeze(0),\n",
    "        \"question\": tokenized_question[\"input_ids\"].squeeze(0),\n",
    "        \"start_pos\": token_start,\n",
    "        \"end_pos\": token_end\n",
    "    }\n",
    "\n",
    "# Preprocess the entire dataset\n",
    "processed_data = []\n",
    "for c, q, a, s in zip(contexts, questions, answers, answer_starts):\n",
    "    item = preprocess_data(c, q, a, s)\n",
    "    if item:\n",
    "        processed_data.append(item)\n",
    "\n",
    "# Convert to PyTorch Dataset\n",
    "class SquadDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.data[idx]\n",
    "        return item[\"context\"], item[\"question\"], item[\"start_pos\"], item[\"end_pos\"]\n",
    "\n",
    "dataset = SquadDataset(processed_data)\n",
    "dataloader = DataLoader(dataset, batch_size=16, shuffle=True)\n",
    "\n",
    "# Step 3: Define the RNN-based model\n",
    "class RNNQuestionAnsweringModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim=128, hidden_dim=128):\n",
    "        super(RNNQuestionAnsweringModel, self).__init__()\n",
    "        \n",
    "        # Embedding layer\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        \n",
    "        # RNN for context and question\n",
    "        self.context_rnn = nn.LSTM(embedding_dim, hidden_dim, bidirectional=True, batch_first=True)\n",
    "        self.question_rnn = nn.LSTM(embedding_dim, hidden_dim, bidirectional=True, batch_first=True)\n",
    "        \n",
    "        # Linear layers for start and end positions\n",
    "        self.start_linear = nn.Linear(hidden_dim * 2, 1)  # Bidirectional RNN has 2x hidden_dim\n",
    "        self.end_linear = nn.Linear(hidden_dim * 2, 1)\n",
    "\n",
    "    def forward(self, context, question):\n",
    "        # Embed context and question\n",
    "        context_embedded = self.embedding(context)  # [batch_size, max_context_len, embedding_dim]\n",
    "        question_embedded = self.embedding(question)  # [batch_size, max_question_len, embedding_dim]\n",
    "        \n",
    "        # Pass through RNNs\n",
    "        context_output, _ = self.context_rnn(context_embedded)  # [batch_size, max_context_len, hidden_dim*2]\n",
    "        question_output, _ = self.question_rnn(question_embedded)  # [batch_size, max_question_len, hidden_dim*2]\n",
    "        \n",
    "        # Use the final question representation (last hidden state)\n",
    "        question_rep = question_output[:, -1, :]  # [batch_size, hidden_dim*2]\n",
    "        question_rep = question_rep.unsqueeze(1).repeat(1, context_output.size(1), 1)  # [batch_size, max_context_len, hidden_dim*2]\n",
    "        \n",
    "        # Concatenate question representation with context\n",
    "        merged = torch.cat([context_output, question_rep], dim=-1)  # [batch_size, max_context_len, hidden_dim*4]\n",
    "        \n",
    "        # Predict start and end positions\n",
    "        start_logits = self.start_linear(merged).squeeze(-1)  # [batch_size, max_context_len]\n",
    "        end_logits = self.end_linear(merged).squeeze(-1)  # [batch_size, max_context_len]\n",
    "        \n",
    "        return start_logits, end_logits\n",
    "\n",
    "# Initialize the model\n",
    "vocab_size = tokenizer.vocab_size\n",
    "model = RNNQuestionAnsweringModel(vocab_size)\n",
    "\n",
    "# Step 4: Define loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "# Step 5: Train the model\n",
    "def train_model(model, dataloader, epochs=3):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        for batch in dataloader:\n",
    "            context, question, start_pos, end_pos = batch\n",
    "            \n",
    "            # Move tensors to device\n",
    "            context = context.to(torch.long)\n",
    "            question = question.to(torch.long)\n",
    "            start_pos = start_pos.to(torch.long)\n",
    "            end_pos = end_pos.to(torch.long)\n",
    "            \n",
    "            # Forward pass\n",
    "            optimizer.zero_grad()\n",
    "            start_logits, end_logits = model(context, question)\n",
    "            \n",
    "            # Compute loss\n",
    "            start_loss = criterion(start_logits, start_pos)\n",
    "            end_loss = criterion(end_logits, end_pos)\n",
    "            loss = (start_loss + end_loss) / 2\n",
    "            \n",
    "            # Backward pass\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "        \n",
    "        print(f\"Epoch {epoch + 1}, Loss: {total_loss / len(dataloader)}\")\n",
    "\n",
    "# train_model(model, dataloader)\n",
    "\n",
    "# # Step 6: Test the model\n",
    "# def predict_answer(model, context, question):\n",
    "#     model.eval()\n",
    "#     with torch.no_grad():\n",
    "#         tokenized_context = tokenizer(context, truncation=True, padding=\"max_length\", max_length=300, return_tensors=\"pt\")\n",
    "#         tokenized_question = tokenizer(question, truncation=True, padding=\"max_length\", max_length=50, return_tensors=\"pt\")\n",
    "        \n",
    "#         context_ids = tokenized_context[\"input_ids\"]\n",
    "#         question_ids = tokenized_question[\"input_ids\"]\n",
    "        \n",
    "#         start_logits, end_logits = model(context_ids, question_ids)\n",
    "#         start_idx = torch.argmax(start_logits, dim=-1).item()\n",
    "#         end_idx = torch.argmax(end_logits, dim=-1).item()\n",
    "        \n",
    "#         tokens = tokenizer.convert_ids_to_tokens(context_ids[0][start_idx:end_idx + 1])\n",
    "#         return tokenizer.convert_tokens_to_string(tokens)\n",
    "\n",
    "# context = \"SQuAD is a dataset for question answering.\"\n",
    "# question = \"What is SQuAD?\"\n",
    "# print(predict_answer(model, context, question))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'context': tensor([  101,  6549,  2135,  1010,  1996,  2082,  2038,  1037,  3234,  2839,\n",
       "          1012, 10234,  1996,  2364,  2311,  1005,  1055,  2751,  8514,  2003,\n",
       "          1037,  3585,  6231,  1997,  1996,  6261,  2984,  1012,  3202,  1999,\n",
       "          2392,  1997,  1996,  2364,  2311,  1998,  5307,  2009,  1010,  2003,\n",
       "          1037,  6967,  6231,  1997,  4828,  2007,  2608,  2039, 14995,  6924,\n",
       "          2007,  1996,  5722,  1000,  2310,  3490,  2618,  4748,  2033, 18168,\n",
       "          5267,  1000,  1012,  2279,  2000,  1996,  2364,  2311,  2003,  1996,\n",
       "         13546,  1997,  1996,  6730,  2540,  1012,  3202,  2369,  1996, 13546,\n",
       "          2003,  1996, 24665, 23052,  1010,  1037, 14042,  2173,  1997,  7083,\n",
       "          1998,  9185,  1012,  2009,  2003,  1037, 15059,  1997,  1996, 24665,\n",
       "         23052,  2012, 10223, 26371,  1010,  2605,  2073,  1996,  6261,  2984,\n",
       "         22353,  2135,  2596,  2000,  3002, 16595,  9648,  4674,  2061, 12083,\n",
       "          9711,  2271,  1999,  8517,  1012,  2012,  1996,  2203,  1997,  1996,\n",
       "          2364,  3298,  1006,  1998,  1999,  1037,  3622,  2240,  2008,  8539,\n",
       "          2083,  1017, 11342,  1998,  1996,  2751,  8514,  1007,  1010,  2003,\n",
       "          1037,  3722,  1010,  2715,  2962,  6231,  1997,  2984,  1012,   102,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0]),\n",
       " 'question': tensor([  101,  2000,  3183,  2106,  1996,  6261,  2984,  9382,  3711,  1999,\n",
       "          8517,  1999, 10223, 26371,  2605,  1029,   102,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0]),\n",
       " 'start_pos': 114,\n",
       " 'end_pos': 121}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoded Context: architecturally, the school has a catholic character. atop the main building ' s gold dome is a golden statue of the virgin mary. immediately in front of the main building and facing it, is a copper statue of christ with arms upraised with the legend \" venite ad me omnes \". next to the main building is the basilica of the sacred heart. immediately behind the basilica is the grotto, a marian place of prayer and reflection. it is a replica of the grotto at lourdes, france where the virgin mary reputedly appeared to saint bernadette soubirous in 1858. at the end of the main drive ( and in a direct line that connects through 3 statues and the gold dome ), is a simple, modern stone statue of mary.\n",
      "Decoded Question: to whom did the virgin mary allegedly appear in 1858 in lourdes france?\n",
      "Decoded Answer: saint bernadette soubirous\n"
     ]
    }
   ],
   "source": [
    "# Example: Decoding a single item from processed_data\n",
    "item = processed_data[0]  # Take the first processed item as an example\n",
    "\n",
    "# Decode the tokenized context\n",
    "decoded_context = tokenizer.decode(item[\"context\"], skip_special_tokens=True)\n",
    "print(\"Decoded Context:\", decoded_context)\n",
    "\n",
    "# Decode the tokenized question\n",
    "decoded_question = tokenizer.decode(item[\"question\"], skip_special_tokens=True)\n",
    "print(\"Decoded Question:\", decoded_question)\n",
    "\n",
    "# Decode the answer using start and end positions\n",
    "start_pos = item[\"start_pos\"]\n",
    "end_pos = item[\"end_pos\"]\n",
    "decoded_answer = tokenizer.decode(item[\"context\"][start_pos:end_pos + 1], skip_special_tokens=True)\n",
    "print(\"Decoded Answer:\", decoded_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoded Text: architecturally, the school has a catholic character. atop the main building ' s gold dome is a golden statue of the virgin mary. immediately in front of the main building and facing it, is a copper statue of christ with arms upraised with the legend \" venite ad me omnes \". next to the main building is the basilica of the sacred heart. immediately behind the basilica is the grotto, a marian place of prayer and reflection. it is a replica of the grotto at lourdes, france where the virgin mary reputedly appeared to saint bernadette soubirous in 1858. at the end of the main drive ( and in a direct line that connects through 3 statues and the gold dome ), is a simple, modern stone statue of mary.\n",
      "\n",
      "Answer Text: saint bernadette soubirous\n"
     ]
    }
   ],
   "source": [
    "from decode_text import TextDecoder\n",
    "decoder = TextDecoder(tokenizer_name=\"bert-base-uncased\")\n",
    "item = processed_data[0]\n",
    "context_token_ids = item['context']\n",
    "start_pos = item['start_pos']\n",
    "end_pos = item['end_pos']\n",
    "decoded_text = decoder.decode_text(context_token_ids)\n",
    "decoded_answer = decoder.decode_answer(context_token_ids, start_pos, end_pos)\n",
    "print(\"Decoded Text: {:s}\\n\".format(decoded_text))\n",
    "print(\"Answer Text: {:s}\".format(decoded_answer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "final_year_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
